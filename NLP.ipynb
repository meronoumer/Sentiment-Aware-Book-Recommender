{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/pandas/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m hard_dependencies, dependency, missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/pandas/compat/__init__.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     is_numpy_dev,\n\u001b[1;32m     17\u001b[0m     np_version_under1p19,\n\u001b[1;32m     18\u001b[0m     np_version_under1p20,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     pa_version_under1p01,\n\u001b[1;32m     22\u001b[0m     pa_version_under2p0,\n\u001b[1;32m     23\u001b[0m     pa_version_under3p0,\n\u001b[1;32m     24\u001b[0m     pa_version_under4p0,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m PY39 \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m9\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/pandas/compat/numpy/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/pandas/util/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     Appender,\n\u001b[1;32m      3\u001b[0m     Substitution,\n\u001b[1;32m      4\u001b[0m     cache_readonly,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     hash_array,\n\u001b[1;32m      9\u001b[0m     hash_pandas_object,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/pandas/util/_decorators.py:14\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Any,\n\u001b[1;32m      8\u001b[0m     Callable,\n\u001b[1;32m      9\u001b[0m     Mapping,\n\u001b[1;32m     10\u001b[0m     cast,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeprecate\u001b[39m(\n\u001b[1;32m     19\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     20\u001b[0m     alternative: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[[F], F]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/pandas/_libs/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/pandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will follow the machine learning life cycle and implement a model to solve a machine learning problem of your choosing. You will select a data set and choose a predictive problem that the data set supports.  You will then inspect the data with your problem in mind and begin to formulate a  project plan. You will then implement the machine learning project plan. \n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build Your DataFrame\n",
    "2. Define Your ML Problem\n",
    "3. Perform exploratory data analysis to understand your data.\n",
    "4. Define Your Project Plan\n",
    "5. Implement Your Project Plan:\n",
    "    * Prepare your data for your model.\n",
    "    * Fit your model to the training data and evaluate your model.\n",
    "    * Improve your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names of the four data sets\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "airbnbDataSet_filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(bookReviewDataSet_filename)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.I am working on the Book Reviews dataset where each review includes text written by a reader and a label showing whether the review was positive or negative.\n",
    "\n",
    "2.Iâ€™m predicting whether a review is positive or negative.\n",
    "The label is the sentiment of the review (positive = 1, negative = 0).\n",
    "\n",
    "This is a supervised learning and classification problem because we are training the model on labeled data because there are only two possible labels: positive or negative.\n",
    "\n",
    "3.The feature being used is the text of the review.\n",
    "I am going to turn this text into numbers using TF-IDF vectorization, which captures the importance of words in the reviews.\n",
    "\n",
    "4. This ML problem is important because it helps companies understand how customers feel about their books.\n",
    "A company (like Audible or Goodreads) can use this model to:\n",
    "\n",
    "Automatically detect negative reviews to improve products, filter or highlight the most helpful reviews and generally get faster insights without needing a human to read every review. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 1 **What data preparation techniques will you use?**\n",
    "\n",
    "\n",
    "To prepare the text data for classification, I'm planning to first clean the reviews by removing punctuation, numbers, and stopwords, and then lowercased all text to ensure consistency. Next, I tokenized the reviews into individual words before vectorizing them using TF-IDF, which converts the text into numerical representations suitable for the model. I also addressed potential class imbalance by checking if there were disproportionate numbers of positive or negative reviews, and planned to use techniques like resampling or class weights if necessary. Finally, any irrelevant columns in the dataset that wouldn't aid prediction were removed.\n",
    "\n",
    "---\n",
    "\n",
    "2 **What machine learning model(s) will you use?**\n",
    "\n",
    "I used:\n",
    "\n",
    "* **Logistic Regression** â€“ as a simple and fast baseline model.\n",
    "* **Random Forest** â€“ to capture non-linear patterns.\n",
    "* **Stacking** â€“ to combine both and hopefully improve accuracy.\n",
    "\n",
    "These models work well with TF-IDF features and classification tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§ª **Other data prep steps? (like scaling)**\n",
    "\n",
    "I'm not prepaaring the data any other way as there is no need to scale data when using **TF-IDF**, Logistic Regression, or Random Forest. TF-IDF already gives normalized values, and tree-based models like Random Forest donâ€™t require scaling.\n",
    "\n",
    "---\n",
    "3. How will you evaluate and improve model performance?**\n",
    "\n",
    "For robust evaluation, I employed cross-validation to assess model performance consistently across the dataset. Model evaluation focused on accuracy for overall correctness, precision, recall, and F1-score to specifically address potential class imbalances, and the ROC-AUC curve to understand the model's ability to distinguish between positive and negative reviews. To enhance performance, I fine-tuned hyperparameters and implemented an ensemble stacking method, with future considerations for exploring deep learning models like BERT for further improvements.\n",
    "\n",
    "---\n",
    "\n",
    "**Techniques used to inspect and analyze data**\n",
    "\n",
    "I used:\n",
    "\n",
    "* `df.describe()` â€“ to get summary stats of the data.\n",
    "* `value_counts()` â€“ to check class distribution (positive vs. negative).\n",
    "* **Seaborn/Matplotlib bar plots** â€“ to visualize class balance.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1973, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data?Â \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My plan for the machine learning lifecycle, focusing on book review classification, begins with Data Preparation While I've already cleaned, lowercased, tokenized, and vectorized the text using TF-IDF, I will ensure no other irrelevant columns remain. I will also explicitly check for class imbalance to prevent bias. \n",
    "For Modeling, I plan to utilize an ensemble approach, specifically stacking with Logistic Regression and Random Forest as my base models, and another Logistic Regression as the meta-model, as this combination has shown good results. My training and evaluation plan involves using 5-fold cross-validation to assess model performance robustly. I will analyze its performance using a comprehensive suite of metrics including Accuracy, Precision, Recall, F1-score (paying close attention to individual class scores due to potential imbalance), and the ROC-AUC curve, which is critical for evaluating the model's ability to discriminate between positive and negative reviews. To improve the model and ensure it generalizes well, I have already tuned hyperparameters for the Random Forest base model using GridSearchCV, and will ensure optimal parameters are used for the Logistic Regression as well. If further performance gains are needed, I might explore additional ensemble techniques, different base models, or even consider more advanced deep learning architectures like BERT in future iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# !pip install spacy\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet# wordnet.synsets('test')\n",
    "from nltk import pos_tag\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "!pip install transformers\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting my second column into numerics\n",
    "df['Positive Review'] = df['Positive Review'].apply(lambda x: 1 if x == True else 0)\n",
    "\n",
    "#checking my class balance of my boolean\n",
    "counts = df['Positive Review'].value_counts()\n",
    "\n",
    "print(counts)\n",
    "plt.bar(counts.index,counts.values,tick_label=['Negative Review (0)', 'Positive Review (1)'], color=['red', 'green'])\n",
    "\n",
    "plt.xlabel('Review Type')\n",
    "plt.ylabel('Number of Reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bar chart shows us that there isn't an imblanace in our negative reviews compared to the positive reviews. Therefore, our model will be able to generalize well to both classes and is likely to provide accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning text data\n",
    "\n",
    "#Lowercasing all my results\n",
    "df['Review'] = df['Review'].str.lower()\n",
    "df['Review']\n",
    "\n",
    "#removing punctuation and any non alphabetic characters\n",
    "pattern_alphanumeric_whitespace = r'[^a-zA-Z0-9\\s]'\n",
    "\n",
    "df['reviews_cleaned'] = df['Review'].str.replace(pattern_alphanumeric_whitespace, '', regex=True)\n",
    "\n",
    "\n",
    "#removing stop words\n",
    "eng_stopwords = stopwords.words('english')\n",
    "\n",
    "filtered_rev = []\n",
    "for review in df['reviews_cleaned']:\n",
    "    word_tokens = word_tokenize(review)\n",
    "    filtered_words = [word for word in word_tokens if word not in eng_stopwords]\n",
    "    filtered_rev.append(filtered_words)\n",
    "            \n",
    "\n",
    "print(\"Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "print(\"Starting\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = pos_tag([word])[0][1][0].lower()\n",
    "    tag_dict = {\"a\": wordnet.ADJ,\n",
    "                \"n\": wordnet.NOUN,\n",
    "                \"v\": wordnet.VERB,\n",
    "                \"r\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatized_reviews = []\n",
    "\n",
    "for review_tokens in filtered_rev:\n",
    "    lemmatized = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in review_tokens]\n",
    "    lemmatized_reviews.append(\" \".join(lemmatized))\n",
    "\n",
    "df['lemmatized_review'] = lemmatized_reviews\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#EDA\n",
    "\n",
    "#\n",
    "df['Review'].str.len().hist()\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Length of Text Against Frequency')\n",
    "plt.show()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Review\"]\n",
    "\n",
    "y = df['Positive Review']\n",
    "#Splitting my data\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y ,test_size = 0.3,random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf model vectorizing \n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Model training and predicting\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "# Finding model's accuracy\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f'Accuracy of our linear regression model : {lr_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest  \n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_tfidf,y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test,y_pred_rf)\n",
    "\n",
    "print(f'Accuracy of our linear regression model : {rf_accuracy}')\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_rf)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred_rf)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning for LR\n",
    "param_grid ={\n",
    "    'C' :[10**i for i in range(-5,5)]\n",
    "}\n",
    "\n",
    "\n",
    "print('Running Grid Search...')\n",
    "\n",
    "\n",
    "grid = GridSearchCV(lr_model, param_grid, cv=5)\n",
    "\n",
    "grid_search = grid.fit(X_train_tfidf,y_train)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C = grid_search.best_params_['C']\n",
    "\n",
    "best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the best logistic regresison model \n",
    "lr_model_best = LogisticRegression(max_iter = 1000,C = best_C)\n",
    "lr_model_best.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hyperparameter tuning FOR RF\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10]\n",
    "}\n",
    "\n",
    "\n",
    "print('Running Grid Search...')\n",
    "\n",
    "\n",
    "grid = GridSearchCV(rf_model, param_grid, cv=5)\n",
    "\n",
    "grid_search = grid.fit(X_train_tfidf,y_train)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_C = grid_search.best_params_['n_estimators']\n",
    "rf_model_best = grid_search.best_estimator_\n",
    "\n",
    "rf_model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('lr', lr_model_best), # A tuple: ('name', unfitted_estimator_object)\n",
    "    ('rf', rf_model_best)  # A tuple: ('name', unfitted_estimator_object)\n",
    "]\n",
    "#building my ensemble model\n",
    "stacked_model = StackingClassifier(estimators = estimators,cv = 5)\n",
    "stacked_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack = stacked_model.predict(X_test_tfidf)\n",
    "stack_accuracy = accuracy_score(y_test, y_pred_stack)\n",
    "\n",
    "print(f\"Accuracy of the stacking model: {stack_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_probs = stacked_model.predict_proba(X_test_tfidf)[:, 1]\n",
    "y_pred = stacked_model.predict(X_test_tfidf)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# AUC Score\n",
    "auc = roc_auc_score(y_test, y_probs)\n",
    "print(f\"AUC Score: {auc:.4f}\")\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph demonstrates that my model demonstrates strong performance in classification. With an overall accuracy of 83%, it correctly predicts outcomes most of the time. Digging deeper, its precision and recall scores (around 83-84%) for both classes are consistent and high, indicating it's reliable in identifying both positive and negative instances without significant bias towards one. Most notably, the AUC score of 0.91, clearly visualized by the ROC curve hugging the top-left corner, signifies that my ensemble model is excellent at distinguishing between the two classes, performing significantly better than random chance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confusion matrix reveals your classification model's performance by showing how many predictions were correct versus incorrect for \"Negative\" and \"Positive\" categories. Out of 592 total predictions, your model correctly identified 236 true negatives and 219 true positives, resulting in about 76.8% overall accuracy. While generally performing well, the model shows a slight tendency to miss positive instances (87 false negatives) more often than it incorrectly flags negative ones as positive (50 false positives). This means it's more likely to classify a genuinely positive book review as negative than vice-versa, which could lead to good books being overlooked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)  \n",
    "sample_indices = np.random.choice(len(X_test), 3, replace=False)\n",
    "\n",
    "print(\" Example Predictions on Test Book Reviews\")\n",
    "print(\"~ \"*80)\n",
    "\n",
    "for index in sample_indices:\n",
    "    review_text = X_test.iloc[index]\n",
    "    true_label = y_test.iloc[index]\n",
    "    \n",
    "    vectorized = tfidf_vectorizer.transform([review_text])\n",
    "    \n",
    "    predicted_label = stacked_model.predict(vectorized)[0]\n",
    "    confidence = stacked_model.predict_proba(vectorized)[0][1] \n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(review_text[:400] + (\"...\" if len(review_text) > 400 else \"\"))\n",
    "    print(f\"\\n True Label:     {'Positive' if true_label else 'Negative'}\")\n",
    "    print(f\" Predicted:      {'Positive' if predicted_label else 'Negative'}\")\n",
    "    print(f\" Confidence:     {confidence:.2f}\")\n",
    "    print(\"~ \"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these three examples, we can see that the stacked model accurately classified all three example book reviews, demonstrating high confidence in its positive predictions (0.81, 0.86) and effectively identifying the negative sentiment with a low positive confidence (0.12), indicating strong performance in discerning both positive and negative tones in the text.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
